{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1897fee",
   "metadata": {},
   "source": [
    "# Assignment 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2b3f89",
   "metadata": {},
   "source": [
    "# Text Summarisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebcbd0f",
   "metadata": {},
   "source": [
    "# Text 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751444f9",
   "metadata": {},
   "source": [
    "#### Setting up a text summarization using NLTK and NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9026beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords #you can remove stop words for speed\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3794d4",
   "metadata": {},
   "source": [
    "#### Processing a paragraph from a text file into individual sentences and then further split them into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a407dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nach der Schule gehe ich oft mit meinen Freundinnen im Park spazieren, manchmal essen wir ein Eis\n",
      "Am Samstag gehen wir oft ins Kino\n",
      "Am Sonntag schlafe ich lange, dann koche ich mit meiner Mutter das Mittagessen\n",
      "Nach dem Essen gehen wir mit dem Hund am See spazieren\n",
      "Sonntag ist mein Lieblingstag!\n"
     ]
    }
   ],
   "source": [
    "file = open(r\"C:\\Users\\ruchitha\\OneDrive\\Documents\\text 1.txt\", \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92bcdd2",
   "metadata": {},
   "source": [
    "#### Print out the sentences after splitting them into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab166c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['Nach', 'der', 'Schule', 'gehe', 'ich', 'oft', 'mit', 'meinen', 'Freundinnen', 'im', 'Park', 'spazieren,', 'manchmal', 'essen', 'wir', 'ein', 'Eis'], ['Am', 'Samstag', 'gehen', 'wir', 'oft', 'ins', 'Kino'], ['Am', 'Sonntag', 'schlafe', 'ich', 'lange,', 'dann', 'koche', 'ich', 'mit', 'meiner', 'Mutter', 'das', 'Mittagessen'], ['Nach', 'dem', 'Essen', 'gehen', 'wir', 'mit', 'dem', 'Hund', 'am', 'See', 'spazieren'], ['Sonntag', 'ist', 'mein', 'Lieblingstag!']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab51d07e",
   "metadata": {},
   "source": [
    "#### Function helps to compute the similarity between two sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0128f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "     # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "          vector1[all_words.index(w)] += 1\n",
    "     # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "          vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c679c3",
   "metadata": {},
   "source": [
    "#### Calculates the similarity between each pair of sentences using the sentence_similarity function and fills in the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "732a8ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.1833397  0.18786729 0.26906912 0.        ]\n",
      " [0.1833397  0.         0.09759001 0.31448545 0.        ]\n",
      " [0.18786729 0.09759001 0.         0.14322297 0.12909944]\n",
      " [0.26906912 0.31448545 0.14322297 0.         0.        ]\n",
      " [0.         0.         0.12909944 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "             if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "             similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeacef2",
   "metadata": {},
   "source": [
    "#### Provides with PageRank scores for each sentence, indicating their relative importance within the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "809a137a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.23102714154777504, 1: 0.21414431407288662, 2: 0.22343931492891606, 3: 0.25743135420660895, 4: 0.07395787524381325}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aa89e8",
   "metadata": {},
   "source": [
    "#### Provides with a ranked list of sentences based on their importance within the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06eb7cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.25743135420660895, ['Nach', 'dem', 'Essen', 'gehen', 'wir', 'mit', 'dem', 'Hund', 'am', 'See', 'spazieren']), (0.23102714154777504, ['Nach', 'der', 'Schule', 'gehe', 'ich', 'oft', 'mit', 'meinen', 'Freundinnen', 'im', 'Park', 'spazieren,', 'manchmal', 'essen', 'wir', 'ein', 'Eis']), (0.22343931492891606, ['Am', 'Sonntag', 'schlafe', 'ich', 'lange,', 'dann', 'koche', 'ich', 'mit', 'meiner', 'Mutter', 'das', 'Mittagessen']), (0.21414431407288662, ['Am', 'Samstag', 'gehen', 'wir', 'oft', 'ins', 'Kino']), (0.07395787524381325, ['Sonntag', 'ist', 'mein', 'Lieblingstag!'])]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\", ranked_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edc4ea4",
   "metadata": {},
   "source": [
    "#### Generates a summary by selecting the top n sentences with the highest PageRank scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c7288fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary? 3\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=4\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88e3ea6",
   "metadata": {},
   "source": [
    "#### Displays the summary, constructed from the top-ranked sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77e47e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " Nach dem Essen gehen wir mit dem Hund am See spazieren. Nach der Schule gehe ich oft mit meinen Freundinnen im Park spazieren, manchmal essen wir ein Eis. Am Sonntag schlafe ich lange, dann koche ich mit meiner Mutter das Mittagessen\n"
     ]
    }
   ],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347b0cbd",
   "metadata": {},
   "source": [
    "# Text 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2d426e",
   "metadata": {},
   "source": [
    "#### Processing a paragraph from a text file into individual sentences and then further split them into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5ab03ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pierre est un jeune garÃ§on de 14 ans\n",
      "Il vit Ã  Paris avec ses parents et sa petite sÅ“ur Julie, Ã¢gÃ©e de 8 ans\n",
      "Toute la petite famille habite dans un grand appartement au 3Ã¨me Ã©tage d'un immeuble situÃ© prÃ¨s de la Tour Eiffel\n",
      "Ainsi, Pierre a le privilÃ¨ge d'admirer chaque jour l'un des monuments les plus visitÃ©s au monde !.Pour se rendre au collÃ¨ge, Pierre prend le mÃ©tro Ã  la station Ecole Militaire et sort au collÃ¨ge Claude Debussy\n",
      "Le trajet ne dure que 20 minutes ! Le week-end, Pierre aime passer du temps en famille\n",
      "Tous les quatre en profitent pour visiter les musÃ©es parisiens, aller au cinÃ©ma, faire du shopping, ou se balader dans l'un des nombreux parcs de la capitale.\n"
     ]
    }
   ],
   "source": [
    "file = open(r\"C:\\Users\\ruchitha\\OneDrive\\Documents\\text 2.txt\", \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6a17bc",
   "metadata": {},
   "source": [
    "#### Print out the sentences after splitting them into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a80519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['Pierre', 'est', 'un', 'jeune', 'garÃ§on', 'de', '14', 'ans'], ['Il', 'vit', 'Ã\\xa0', 'Paris', 'avec', 'ses', 'parents', 'et', 'sa', 'petite', 'sÅ“ur', 'Julie,', 'Ã¢gÃ©e', 'de', '8', 'ans'], ['Toute', 'la', 'petite', 'famille', 'habite', 'dans', 'un', 'grand', 'appartement', 'au', '3Ã¨me', 'Ã©tage', \"d'un\", 'immeuble', 'situÃ©', 'prÃ¨s', 'de', 'la', 'Tour', 'Eiffel'], ['Ainsi,', 'Pierre', 'a', 'le', 'privilÃ¨ge', \"d'admirer\", 'chaque', 'jour', \"l'un\", 'des', 'monuments', 'les', 'plus', 'visitÃ©s', 'au', 'monde', '!.Pour', 'se', 'rendre', 'au', 'collÃ¨ge,', 'Pierre', 'prend', 'le', 'mÃ©tro', 'Ã\\xa0', 'la', 'station', 'Ecole', 'Militaire', 'et', 'sort', 'au', 'collÃ¨ge', 'Claude', 'Debussy'], ['Le', 'trajet', 'ne', 'dure', 'que', '20', 'minutes', '!', 'Le', 'week-end,', 'Pierre', 'aime', 'passer', 'du', 'temps', 'en', 'famille'], ['Tous', 'les', 'quatre', 'en', 'profitent', 'pour', 'visiter', 'les', 'musÃ©es', 'parisiens,', 'aller', 'au', 'cinÃ©ma,', 'faire', 'du', 'shopping,', 'ou', 'se', 'balader', 'dans', \"l'un\", 'des', 'nombreux', 'parcs', 'de', 'la', 'capitale.']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e1d48b",
   "metadata": {},
   "source": [
    "#### Function helps to compute the similarity between two sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d57f83a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "     # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "          vector1[all_words.index(w)] += 1\n",
    "     # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "          vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370a6665",
   "metadata": {},
   "source": [
    "#### Calculates the similarity between each pair of sentences using the sentence_similarity function and fills in the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb4ab4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.1767767  0.15075567 0.10425721 0.08111071 0.06565322]\n",
      " [0.1767767  0.         0.10660036 0.07372098 0.         0.04642383]\n",
      " [0.15075567 0.10660036 0.         0.15717365 0.0489116  0.1979519 ]\n",
      " [0.10425721 0.07372098 0.15717365 0.         0.20295303 0.24641356]\n",
      " [0.08111071 0.         0.0489116  0.20295303 0.         0.08520286]\n",
      " [0.06565322 0.04642383 0.1979519  0.24641356 0.08520286 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "             if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "             similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753cc2c7",
   "metadata": {},
   "source": [
    "#### Provides with PageRank scores for each sentence, indicating their relative importance within the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b63bfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.16768590609090062, 1: 0.12259565995486688, 2: 0.18649891276878533, 3: 0.2178393851371543, 4: 0.12496980583094575, 5: 0.18041033021734693}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25bf692",
   "metadata": {},
   "source": [
    "#### Provides with a ranked list of sentences based on their importance within the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec7f1751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.2178393851371543, ['Ainsi,', 'Pierre', 'a', 'le', 'privilÃ¨ge', \"d'admirer\", 'chaque', 'jour', \"l'un\", 'des', 'monuments', 'les', 'plus', 'visitÃ©s', 'au', 'monde', '!.Pour', 'se', 'rendre', 'au', 'collÃ¨ge,', 'Pierre', 'prend', 'le', 'mÃ©tro', 'Ã\\xa0', 'la', 'station', 'Ecole', 'Militaire', 'et', 'sort', 'au', 'collÃ¨ge', 'Claude', 'Debussy']), (0.18649891276878533, ['Toute', 'la', 'petite', 'famille', 'habite', 'dans', 'un', 'grand', 'appartement', 'au', '3Ã¨me', 'Ã©tage', \"d'un\", 'immeuble', 'situÃ©', 'prÃ¨s', 'de', 'la', 'Tour', 'Eiffel']), (0.18041033021734693, ['Tous', 'les', 'quatre', 'en', 'profitent', 'pour', 'visiter', 'les', 'musÃ©es', 'parisiens,', 'aller', 'au', 'cinÃ©ma,', 'faire', 'du', 'shopping,', 'ou', 'se', 'balader', 'dans', \"l'un\", 'des', 'nombreux', 'parcs', 'de', 'la', 'capitale.']), (0.16768590609090062, ['Pierre', 'est', 'un', 'jeune', 'garÃ§on', 'de', '14', 'ans']), (0.12496980583094575, ['Le', 'trajet', 'ne', 'dure', 'que', '20', 'minutes', '!', 'Le', 'week-end,', 'Pierre', 'aime', 'passer', 'du', 'temps', 'en', 'famille']), (0.12259565995486688, ['Il', 'vit', 'Ã\\xa0', 'Paris', 'avec', 'ses', 'parents', 'et', 'sa', 'petite', 'sÅ“ur', 'Julie,', 'Ã¢gÃ©e', 'de', '8', 'ans'])]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\", ranked_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2053c79",
   "metadata": {},
   "source": [
    "#### Generates a summary by selecting the top n sentences with the highest PageRank scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b94bab0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary? 5\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=5\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8049e9d",
   "metadata": {},
   "source": [
    "#### Displays the summary, constructed from the top-ranked sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af2097f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " Ainsi, Pierre a le privilÃ¨ge d'admirer chaque jour l'un des monuments les plus visitÃ©s au monde !.Pour se rendre au collÃ¨ge, Pierre prend le mÃ©tro Ã  la station Ecole Militaire et sort au collÃ¨ge Claude Debussy. Toute la petite famille habite dans un grand appartement au 3Ã¨me Ã©tage d'un immeuble situÃ© prÃ¨s de la Tour Eiffel. Tous les quatre en profitent pour visiter les musÃ©es parisiens, aller au cinÃ©ma, faire du shopping, ou se balader dans l'un des nombreux parcs de la capitale.. Pierre est un jeune garÃ§on de 14 ans. Le trajet ne dure que 20 minutes ! Le week-end, Pierre aime passer du temps en famille\n"
     ]
    }
   ],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee13bbf",
   "metadata": {},
   "source": [
    "# Text 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7e0eea",
   "metadata": {},
   "source": [
    "#### Processing a paragraph from a text file into individual sentences and then further split them into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d324021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mi abuelo TomÃ¡s.Mi abuelo TomÃ¡s tiene ochenta aÃ±os y vive con nosotros\n",
      "Tiene buena salud, aunque a veces dice que le duele una pierna, pero camina Ã¡gilmente cuando le llaman sus amigos para jugar a las cartas despuÃ©s de comer.Todos los domingos me lleva a ver el futbol y despuÃ©s me compra un helado.En vacaciones siempre viene con nosotros y le gusta mucho ir a la playa\n",
      "A veces discute con mi padre cuando quiere ir a la montaÃ±a\n",
      "Al final siempre se sale con la suya y mi padre acaba cediendo\n",
      "Para compensarle siempre nos invita el primer dÃ­a de vacaciones a un buen restaurante.Quiero mucho a mi abuelo.\n"
     ]
    }
   ],
   "source": [
    "file = open(r\"C:\\Users\\ruchitha\\OneDrive\\Documents\\text 3.txt\", \"r\")\n",
    "#This file contains one paragraph of multiple sentences\n",
    "filedata = file.readlines()\n",
    "article = filedata[0].split(\". \") #Just do the first paragraph\n",
    "\n",
    "sentences = []\n",
    "for sentence in article:\n",
    "    print(sentence)\n",
    "    sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a45eca",
   "metadata": {},
   "source": [
    "#### Print out the sentences after splitting them into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc535653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences are  [['Mi', 'abuelo', 'TomÃ¡s.Mi', 'abuelo', 'TomÃ¡s', 'tiene', 'ochenta', 'aÃ±os', 'y', 'vive', 'con', 'nosotros'], ['Tiene', 'buena', 'salud,', 'aunque', 'a', 'veces', 'dice', 'que', 'le', 'duele', 'una', 'pierna,', 'pero', 'camina', 'Ã¡gilmente', 'cuando', 'le', 'llaman', 'sus', 'amigos', 'para', 'jugar', 'a', 'las', 'cartas', 'despuÃ©s', 'de', 'comer.Todos', 'los', 'domingos', 'me', 'lleva', 'a', 'ver', 'el', 'futbol', 'y', 'despuÃ©s', 'me', 'compra', 'un', 'helado.En', 'vacaciones', 'siempre', 'viene', 'con', 'nosotros', 'y', 'le', 'gusta', 'mucho', 'ir', 'a', 'la', 'playa'], ['A', 'veces', 'discute', 'con', 'mi', 'padre', 'cuando', 'quiere', 'ir', 'a', 'la', 'montaÃ±a'], ['Al', 'final', 'siempre', 'se', 'sale', 'con', 'la', 'suya', 'y', 'mi', 'padre', 'acaba', 'cediendo'], ['Para', 'compensarle', 'siempre', 'nos', 'invita', 'el', 'primer', 'dÃ\\xada', 'de', 'vacaciones', 'a', 'un', 'buen', 'restaurante.Quiero', 'mucho', 'a', 'mi', 'abuelo.']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentences are \", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb2b83",
   "metadata": {},
   "source": [
    "#### Function helps to compute the similarity between two sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04484291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2 ):\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "     # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "          vector1[all_words.index(w)] += 1\n",
    "     # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "          vector2[all_words.index(w)] += 1\n",
    "    return 1 - cosine_distance(vector1, vector2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dc748a",
   "metadata": {},
   "source": [
    "#### Calculates the similarity between each pair of sentences using the sentence_similarity function and fills in the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc2248df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smilarity matrix \n",
      " [[0.         0.15034619 0.14285714 0.22237479 0.05976143]\n",
      " [0.15034619 0.         0.39090011 0.15602162 0.37736595]\n",
      " [0.14285714 0.39090011 0.         0.29649973 0.29880715]\n",
      " [0.22237479 0.15602162 0.29649973 0.         0.12403473]\n",
      " [0.05976143 0.37736595 0.29880715 0.12403473 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "             if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "             similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2])\n",
    "\n",
    "print(\"Smilarity matrix \\n\", similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd556dab",
   "metadata": {},
   "source": [
    "#### Provides with PageRank scores for each sentence, indicating their relative importance within the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd70062c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores {0: 0.13960409985527306, 1: 0.23626328715591705, 2: 0.24745969139965174, 3: 0.18389283385742253, 4: 0.19278008773173516}\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Rank sentences in similarity martix\n",
    "sentence_similarity_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(sentence_similarity_graph)\n",
    "print(\"scores\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e299eb54",
   "metadata": {},
   "source": [
    "#### Provides with a ranked list of sentences based on their importance within the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1b92bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes of top ranked_sentence order are \n",
      "\n",
      " [(0.24745969139965174, ['A', 'veces', 'discute', 'con', 'mi', 'padre', 'cuando', 'quiere', 'ir', 'a', 'la', 'montaÃ±a']), (0.23626328715591705, ['Tiene', 'buena', 'salud,', 'aunque', 'a', 'veces', 'dice', 'que', 'le', 'duele', 'una', 'pierna,', 'pero', 'camina', 'Ã¡gilmente', 'cuando', 'le', 'llaman', 'sus', 'amigos', 'para', 'jugar', 'a', 'las', 'cartas', 'despuÃ©s', 'de', 'comer.Todos', 'los', 'domingos', 'me', 'lleva', 'a', 'ver', 'el', 'futbol', 'y', 'despuÃ©s', 'me', 'compra', 'un', 'helado.En', 'vacaciones', 'siempre', 'viene', 'con', 'nosotros', 'y', 'le', 'gusta', 'mucho', 'ir', 'a', 'la', 'playa']), (0.19278008773173516, ['Para', 'compensarle', 'siempre', 'nos', 'invita', 'el', 'primer', 'dÃ\\xada', 'de', 'vacaciones', 'a', 'un', 'buen', 'restaurante.Quiero', 'mucho', 'a', 'mi', 'abuelo.']), (0.18389283385742253, ['Al', 'final', 'siempre', 'se', 'sale', 'con', 'la', 'suya', 'y', 'mi', 'padre', 'acaba', 'cediendo']), (0.13960409985527306, ['Mi', 'abuelo', 'TomÃ¡s.Mi', 'abuelo', 'TomÃ¡s', 'tiene', 'ochenta', 'aÃ±os', 'y', 'vive', 'con', 'nosotros'])]\n"
     ]
    }
   ],
   "source": [
    "# Step 4 - Sort the rank and pick top sentences\n",
    "ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "print(\"Indexes of top ranked_sentence order are \\n\\n\", ranked_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89e5147",
   "metadata": {},
   "source": [
    "#### Generates a summary by selecting the top n sentences with the highest PageRank scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "29fc8b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many sentences do you want in the summary? 2\n"
     ]
    }
   ],
   "source": [
    "#Step 5 - How many sentences to pick\n",
    "n = int(input(\"How many sentences do you want in the summary? \"))\n",
    "#n=3\n",
    "summarize_text = []\n",
    "for i in range(n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af22243",
   "metadata": {},
   "source": [
    "#### Displays the summary, constructed from the top-ranked sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74baad18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " A veces discute con mi padre cuando quiere ir a la montaÃ±a. Tiene buena salud, aunque a veces dice que le duele una pierna, pero camina Ã¡gilmente cuando le llaman sus amigos para jugar a las cartas despuÃ©s de comer.Todos los domingos me lleva a ver el futbol y despuÃ©s me compra un helado.En vacaciones siempre viene con nosotros y le gusta mucho ir a la playa\n"
     ]
    }
   ],
   "source": [
    "# Step 6 - Offcourse, output the summarize text\n",
    "print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e148fa06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
